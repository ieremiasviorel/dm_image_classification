Epoch 1/10
513/513 [==============================] - 32293s 63s/step - loss: 0.6569 - acc: 0.8446 - val_loss: 0.3378 - val_acc: 0.9094

Epoch 00001: saving model to /content/gdrive/My Drive/dm_image_classification/weights-improvement-naslarge-01.hdf5

Classification Report
C:\Program Files\Python37\lib\site-packages\sklearn\metrics\_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
              precision    recall  f1-score   support

           0       0.93      0.84      0.88        31
           1       0.85      0.95      0.90        37
           2       0.96      0.92      0.94        51
           3       0.94      1.00      0.97        30
           4       0.84      0.88      0.86        43
           5       0.97      0.95      0.96        38
           6       0.93      0.95      0.94        40
           7       0.49      0.91      0.64        35
           8       0.91      0.89      0.90        35
           9       1.00      0.98      0.99        48
          10       1.00      0.97      0.99        35
          11       0.90      0.92      0.91        39
          12       0.93      0.97      0.95        38
          13       0.97      1.00      0.99        35
          14       0.91      1.00      0.96        32
          15       0.86      0.81      0.83        31
          16       0.78      0.91      0.84        32
          17       1.00      0.90      0.95        30
          18       1.00      0.97      0.98        31
          19       0.78      0.98      0.87        44
          20       0.95      0.97      0.96        37
          21       0.94      0.89      0.92        38
          22       1.00      1.00      1.00        38
          23       0.98      1.00      0.99        40
          24       0.97      0.90      0.93        31
          25       0.97      0.97      0.97        40
          26       0.97      0.79      0.87        47
          27       1.00      0.91      0.95        32
          28       0.76      0.90      0.82        31
          29       0.81      0.64      0.71        33
          30       1.00      1.00      1.00        37
          31       0.97      1.00      0.99        35
          32       0.92      0.97      0.95        36
          33       0.91      0.94      0.93        34
          34       0.89      0.89      0.89        35
          35       0.94      0.89      0.92        37
          36       0.86      0.97      0.91        33
          37       0.84      0.84      0.84        32
          38       0.94      0.78      0.85        40
          39       0.93      0.98      0.95        41
          40       0.95      0.98      0.96        41
          41       0.89      0.97      0.93        40
          42       1.00      0.93      0.96        40
          43       0.97      0.97      0.97        36
          44       1.00      0.05      0.10        37
          45       0.88      0.90      0.89        31
          46       1.00      0.97      0.98        32
          47       0.88      0.90      0.89        31
          48       1.00      0.94      0.97        32
          49       0.85      0.98      0.91        42
          50       0.97      0.84      0.90        37
          51       0.97      1.00      0.98        32
          52       0.89      0.94      0.91        34
          53       1.00      0.71      0.83        38
          54       0.86      1.00      0.93        31
          55       1.00      0.94      0.97        31
          56       0.91      0.97      0.94        30
          57       0.94      0.91      0.93        35
          58       0.97      0.94      0.96        34
          59       1.00      0.97      0.98        31
          60       0.97      0.97      0.97        31
          61       0.86      0.97      0.91        33
          62       0.97      1.00      0.98        31
          63       1.00      0.97      0.98        31
          64       0.88      0.94      0.91        31
          65       0.94      1.00      0.97        30
          66       0.97      0.94      0.95        32
          67       0.97      0.97      0.97        30
          68       1.00      0.94      0.97        32
          69       0.96      0.81      0.88        31
          70       0.91      1.00      0.95        30
          71       1.00      0.90      0.95        30
          72       0.97      1.00      0.98        31
          73       1.00      0.97      0.98        30
          74       0.97      1.00      0.98        30
          75       0.94      0.97      0.95        31
          76       0.64      0.97      0.77        31
          77       0.97      1.00      0.98        31
          78       1.00      0.97      0.99        34
          79       0.91      0.62      0.74        32
          80       0.61      0.61      0.61        31
          81       0.70      1.00      0.82        30
          82       0.96      0.90      0.93        30
          83       1.00      0.97      0.98        31
          84       1.00      0.97      0.98        31
          85       1.00      0.90      0.95        30
          86       0.97      0.92      0.94        37
          87       0.82      0.97      0.89        34
          88       0.89      0.93      0.91        44
          89       0.96      0.77      0.86        31
          90       0.95      0.85      0.90        41
          91       1.00      0.97      0.98        31
          92       0.94      1.00      0.97        32
          93       0.97      0.94      0.95        31
          94       0.76      1.00      0.86        32
          95       0.97      0.94      0.95        32
          96       1.00      0.97      0.99        34
          97       0.39      0.87      0.54        30
          98       0.86      0.89      0.88        36
          99       0.00      0.00      0.00        39
         100       0.97      1.00      0.98        30
         101       0.97      0.90      0.94        42
         102       1.00      0.90      0.95        40
         103       0.98      1.00      0.99        42
         104       0.95      0.92      0.94        39
         105       0.91      0.98      0.94        43
         106       1.00      0.98      0.99        44
         107       1.00      0.93      0.96        44
         108       1.00      1.00      1.00        40
         109       1.00      1.00      1.00        32
         110       0.91      0.97      0.94        31
         111       0.92      0.97      0.95        37
         112       0.96      0.87      0.92        31
         113       1.00      0.48      0.65        31
         114       0.53      1.00      0.69        31
         115       0.91      0.66      0.76        32
         116       1.00      0.97      0.98        31
         117       1.00      0.81      0.90        32
         118       1.00      0.93      0.97        30
         119       0.97      1.00      0.99        34

    accuracy                           0.91      4162
   macro avg       0.92      0.91      0.90      4162
weighted avg       0.92      0.91      0.90      4162

Confusion Matrix
.\predict.py:71: DeprecationWarning: This function is deprecated. Please call randint(0, 4162 + 1) instead
  imageno=np.random.random_integers(low=0, high=validation_generator.samples)
split/val\n02086079-Pekinese\n02086079_13897.jpg
0.98567826   :   (3, 'n02086079-Pekinese')
0.0059971935   :   (4, 'n02086240-Shih-Tzu')
0.00237203   :   (56, 'n02099601-golden_retriever')
PS C:\Users\Sebi\study\master\datamining\dm_image_classification>