Found 16418 images belonging to 120 classes.
Found 4162 images belonging to 120 classes.
Epoch 1/10
2020-01-11 18:57:17.602655: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 411041792 exceeds 10% of system memory.
2020-01-11 18:57:17.844686: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 411041792 exceeds 10% of system memory.
  1/513 [..............................] - ETA: 1:22:29 - loss: 9.2928 - accuracy: 0.03122020-01-11 18:57:26.923200: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 411041792 exceeds 10% of system memory.
2020-01-11 18:57:27.181481: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 411041792 exceeds 10% of system memory.
  2/513 [..............................] - ETA: 1:20:27 - loss: 9.9749 - accuracy: 0.04692020-01-11 18:57:36.152564: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 411041792 exceeds 10% of system memory.
513/513 [==============================] - 5219s 10s/step - loss: 1.6603 - accuracy: 0.5571 - val_loss: 0.7381 - val_accuracy: 0.6615

Epoch 00001: saving model to weights-improvement-01.hdf5
Epoch 2/10
513/513 [==============================] - 5059s 10s/step - loss: 0.9166 - accuracy: 0.7181 - val_loss: 1.3290 - val_accuracy: 0.7019

Epoch 00002: saving model to weights-improvement-02.hdf5
Epoch 3/10
513/513 [==============================] - 5087s 10s/step - loss: 0.7045 - accuracy: 0.7787 - val_loss: 1.0720 - val_accuracy: 0.7039

Epoch 00003: saving model to weights-improvement-03.hdf5
Epoch 4/10
513/513 [==============================] - 5033s 10s/step - loss: 0.6081 - accuracy: 0.8030 - val_loss: 0.6914 - val_accuracy: 0.7213

Epoch 00004: saving model to weights-improvement-04.hdf5
Epoch 5/10
513/513 [==============================] - 5029s 10s/step - loss: 0.5037 - accuracy: 0.8340 - val_loss: 1.2605 - val_accuracy: 0.6867

Epoch 00005: saving model to weights-improvement-05.hdf5
Epoch 6/10
513/513 [==============================] - 5014s 10s/step - loss: 0.4766 - accuracy: 0.8460 - val_loss: 2.1784 - val_accuracy: 0.7145

Epoch 00006: saving model to weights-improvement-06.hdf5
Epoch 7/10
513/513 [==============================] - 5021s 10s/step - loss: 0.3927 - accuracy: 0.8707 - val_loss: 0.9332 - val_accuracy: 0.7215

Epoch 00007: saving model to weights-improvement-07.hdf5
Epoch 8/10
513/513 [==============================] - 5017s 10s/step - loss: 0.3632 - accuracy: 0.8811 - val_loss: 1.9306 - val_accuracy: 0.7254

Epoch 00008: saving model to weights-improvement-08.hdf5
Epoch 9/10
513/513 [==============================] - 5009s 10s/step - loss: 0.3332 - accuracy: 0.8947 - val_loss: 1.4425 - val_accuracy: 0.7346

Epoch 00009: saving model to weights-improvement-09.hdf5
Epoch 10/10
513/513 [==============================] - 5004s 10s/step - loss: 0.2957 - accuracy: 0.9053 - val_loss: 0.7952 - val_accuracy: 0.7223

Epoch 00010: saving model to weights-improvement-10.hdf5
[[2.7850094e-01 9.0166594e-08 6.7897104e-06 ... 6.6894077e-04
  9.1743605e-06 3.4256215e-07]
 [9.8290908e-01 2.8001665e-10 2.9708605e-08 ... 4.0538728e-09
  2.7147875e-09 3.1941628e-12]
 [3.1140729e-04 9.7535480e-10 5.2715693e-10 ... 4.5042484e-07
  2.0921985e-07 2.5806636e-07]
 ...
 [2.5494810e-05 7.2258882e-07 3.9868934e-07 ... 3.7375790e-05
  1.2679921e-03 9.7406030e-01]
 [1.0724819e-25 7.3513835e-37 0.0000000e+00 ... 1.1881453e-23
  1.1067040e-24 1.0000000e+00]
 [9.5493494e-31 0.0000000e+00 0.0000000e+00 ... 4.7505087e-35
  1.2288191e-32 1.0000000e+00]]
[107   0  86 ... 119 119 119]
Classification Report
              precision    recall  f1-score   support

           0       0.87      0.42      0.57        31
           1       0.82      0.76      0.79        37
           2       1.00      0.57      0.72        51
           3       0.52      0.97      0.67        30
           4       0.54      0.30      0.39        43
           5       0.83      0.89      0.86        38
           6       0.94      0.82      0.88        40
           7       0.56      0.66      0.61        35
           8       0.66      0.71      0.68        35
           9       0.80      0.94      0.87        48
          10       0.44      0.86      0.58        35
          11       0.92      0.31      0.46        39
          12       0.71      0.66      0.68        38
          13       0.93      0.74      0.83        35
          14       0.63      0.81      0.71        32
          15       0.41      0.58      0.48        31
          16       0.59      0.59      0.59        32
          17       0.55      0.70      0.62        30
          18       0.71      0.71      0.71        31
          19       0.67      0.70      0.69        44
          20       0.86      0.65      0.74        37
          21       0.67      0.58      0.62        38
          22       0.73      0.92      0.81        38
          23       0.92      0.88      0.90        40
          24       0.80      0.77      0.79        31
          25       0.83      0.88      0.85        40
          26       0.89      0.66      0.76        47
          27       0.81      0.94      0.87        32
          28       0.29      0.65      0.40        31
          29       0.58      0.33      0.42        33
          30       0.85      0.92      0.88        37
          31       0.74      0.89      0.81        35
          32       0.86      0.69      0.77        36
          33       0.65      0.76      0.70        34
          34       0.70      0.46      0.55        35
          35       0.67      0.81      0.73        37
          36       0.74      0.42      0.54        33
          37       0.78      0.56      0.65        32
          38       0.47      0.60      0.53        40
          39       0.94      0.83      0.88        41
          40       0.86      0.61      0.71        41
          41       0.84      0.78      0.81        40
          42       0.77      0.75      0.76        40
          43       0.71      0.89      0.79        36
          44       0.85      0.92      0.88        37
          45       0.66      0.74      0.70        31
          46       0.90      0.59      0.72        32
          47       0.46      0.58      0.51        31
          48       0.81      0.69      0.75        32
          49       0.72      0.62      0.67        42
          50       0.63      0.78      0.70        37
          51       0.69      0.69      0.69        32
          52       0.74      0.85      0.79        34
          53       0.38      0.68      0.49        38
          54       0.73      0.71      0.72        31
          55       0.81      0.81      0.81        31
          56       0.70      0.70      0.70        30
          57       0.71      0.63      0.67        35
          58       0.71      0.85      0.77        34
          59       0.74      0.94      0.83        31
          60       0.77      0.97      0.86        31
          61       0.83      0.73      0.77        33
          62       0.74      0.94      0.83        31
          63       0.92      0.74      0.82        31
          64       0.70      0.45      0.55        31
          65       0.80      0.93      0.86        30
          66       0.69      0.62      0.66        32
          67       0.51      0.90      0.65        30
          68       0.83      0.62      0.71        32
          69       0.88      0.71      0.79        31
          70       0.94      0.57      0.71        30
          71       0.80      0.80      0.80        30
          72       0.76      0.81      0.78        31
          73       0.89      0.83      0.86        30
          74       0.91      0.70      0.79        30
          75       0.70      0.74      0.72        31
          76       0.71      0.65      0.68        31
          77       0.97      0.94      0.95        31
          78       0.94      0.85      0.89        34
          79       0.60      0.78      0.68        32
          80       0.57      0.26      0.36        31
          81       0.66      0.63      0.64        30
          82       0.59      0.73      0.66        30
          83       0.90      0.87      0.89        31
          84       0.75      0.68      0.71        31
          85       0.59      0.77      0.67        30
          86       0.72      0.62      0.67        37
          87       0.75      0.53      0.62        34
          88       0.83      0.77      0.80        44
          89       0.54      0.71      0.61        31
          90       0.89      0.78      0.83        41
          91       0.73      0.77      0.75        31
          92       0.87      0.84      0.86        32
          93       0.62      0.68      0.65        31
          94       1.00      0.62      0.77        32
          95       0.71      0.69      0.70        32
          96       0.82      0.97      0.89        34
          97       0.48      0.37      0.42        30
          98       0.64      0.83      0.72        36
          99       0.55      0.44      0.49        39
         100       0.75      0.90      0.82        30
         101       0.76      0.83      0.80        42
         102       0.89      0.85      0.87        40
         103       0.94      0.81      0.87        42
         104       0.77      0.62      0.69        39
         105       0.74      0.65      0.69        43
         106       0.87      0.75      0.80        44
         107       0.80      0.80      0.80        44
         108       1.00      0.75      0.86        40
         109       0.78      1.00      0.88        32
         110       0.93      0.90      0.92        31
         111       0.67      0.84      0.75        37
         112       0.77      0.55      0.64        31
         113       0.54      0.71      0.61        31
         114       0.78      0.23      0.35        31
         115       0.57      0.78      0.66        32
         116       0.88      0.90      0.89        31
         117       0.74      0.72      0.73        32
         119       0.75      0.97      0.85        34

    accuracy                           0.72      4162
   macro avg       0.74      0.72      0.72      4162
weighted avg       0.75      0.72      0.72      4162

Confusion Matrix
.\classification.py:112: DeprecationWarning: This function is deprecated. Please call randint(0, 4162 + 1) instead
  imageno = np.random.random_integers(low=0, high=validation_generator.samples)
./split/val\n02089867-Walker_hound\n02089867_2010.jpg
0.9336505   :   (16, 'n02089973-English_foxhound')
0.05337574   :   (15, 'n02089867-Walker_hound')
0.0124718975   :   (11, 'n02088364-beagle')
