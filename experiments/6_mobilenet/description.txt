Found 16418 images belonging to 120 classes.
Found 4162 images belonging to 120 classes.
Epoch 1/10
513/513 [==============================] - 1779s 3s/step - loss: 2.0743 - accuracy: 0.4289 - val_loss: 1.4072 - val_accuracy: 0.5635

Epoch 00001: saving model to weights-improvement-mobilenet-01.hdf5
Epoch 2/10
513/513 [==============================] - 1736s 3s/step - loss: 1.1723 - accuracy: 0.6347 - val_loss: 1.0335 - val_accuracy: 0.6630

Epoch 00002: saving model to weights-improvement-mobilenet-02.hdf5
Epoch 3/10
513/513 [==============================] - 1757s 3s/step - loss: 0.9676 - accuracy: 0.6983 - val_loss: 1.9969 - val_accuracy: 0.6852

Epoch 00003: saving model to weights-improvement-mobilenet-03.hdf5
Epoch 4/10
513/513 [==============================] - 1753s 3s/step - loss: 0.8525 - accuracy: 0.7274 - val_loss: 2.1340 - val_accuracy: 0.6857

Epoch 00004: saving model to weights-improvement-mobilenet-04.hdf5
Epoch 5/10
513/513 [==============================] - 1746s 3s/step - loss: 0.7524 - accuracy: 0.7596 - val_loss: 2.9823 - val_accuracy: 0.6881

Epoch 00005: saving model to weights-improvement-mobilenet-05.hdf5
Epoch 6/10
513/513 [==============================] - 1716s 3s/step - loss: 0.6789 - accuracy: 0.7832 - val_loss: 2.4557 - val_accuracy: 0.6811

Epoch 00006: saving model to weights-improvement-mobilenet-06.hdf5
Epoch 7/10
513/513 [==============================] - 1625s 3s/step - loss: 0.6110 - accuracy: 0.8003 - val_loss: 1.2152 - val_accuracy: 0.6847

Epoch 00007: saving model to weights-improvement-mobilenet-07.hdf5
Epoch 8/10
513/513 [==============================] - 1625s 3s/step - loss: 0.5369 - accuracy: 0.8244 - val_loss: 1.5138 - val_accuracy: 0.7034

Epoch 00008: saving model to weights-improvement-mobilenet-08.hdf5
Epoch 9/10
513/513 [==============================] - 1627s 3s/step - loss: 0.4663 - accuracy: 0.8470 - val_loss: 0.5312 - val_accuracy: 0.6889

Epoch 00009: saving model to weights-improvement-mobilenet-09.hdf5
Epoch 10/10
513/513 [==============================] - 1629s 3s/step - loss: 0.4575 - accuracy: 0.8505 - val_loss: 1.0974 - val_accuracy: 0.6896

Epoch 00010: saving model to weights-improvement-mobilenet-10.hdf5
[[2.4766086e-03 1.4674447e-07 7.9113033e-10 ... 6.6101381e-11
  3.6408709e-10 3.2410335e-13]
 [4.3551660e-01 2.0332427e-06 2.3955501e-05 ... 1.9459089e-03
  6.7312458e-06 3.9479524e-05]
 [4.3780550e-02 5.5887696e-05 2.4085864e-06 ... 6.1647312e-05
  1.1513198e-05 4.2088515e-05]
 ...
 [6.7357621e-03 2.7954485e-03 1.2378330e-02 ... 2.4949883e-03
  9.6794398e-04 1.6062994e-03]
 [1.1796782e-04 1.8223452e-09 3.2785569e-11 ... 4.9005939e-05
  4.7324782e-05 1.0929408e-01]
 [4.4440438e-09 1.8319654e-13 4.7458055e-17 ... 1.1686485e-10
  3.0839526e-09 9.9999976e-01]]
[  6   0  44 ...  26 112 119]
Classification Report
              precision    recall  f1-score   support

           0       0.87      0.42      0.57        31
           1       0.69      0.78      0.73        37
           2       0.69      0.84      0.76        51
           3       0.86      0.63      0.73        30
           4       0.76      0.65      0.70        43
           5       0.89      0.45      0.60        38
           6       0.47      0.97      0.63        40
           7       0.78      0.60      0.68        35
           8       0.50      0.77      0.61        35
           9       1.00      0.77      0.87        48
          10       0.90      0.77      0.83        35
          11       0.92      0.28      0.43        39
          12       0.97      0.74      0.84        38
          13       0.89      0.69      0.77        35
          14       0.83      0.78      0.81        32
          15       0.48      0.48      0.48        31
          16       0.45      0.81      0.58        32
          17       0.67      0.53      0.59        30
          18       0.85      0.71      0.77        31
          19       0.66      0.75      0.70        44
          20       0.94      0.43      0.59        37
          21       0.62      0.63      0.62        38
          22       0.88      0.92      0.90        38
          23       0.97      0.80      0.88        40
          24       0.72      0.68      0.70        31
          25       0.76      0.95      0.84        40
          26       0.79      0.79      0.79        47
          27       1.00      0.66      0.79        32
          28       0.40      0.55      0.47        31
          29       0.37      0.73      0.49        33
          30       0.86      0.68      0.76        37
          31       0.88      0.63      0.73        35
          32       0.86      0.83      0.85        36
          33       0.52      0.88      0.65        34
          34       0.28      0.80      0.41        35
          35       0.61      0.46      0.52        37
          36       0.59      0.52      0.55        33
          37       0.41      0.72      0.52        32
          38       0.65      0.33      0.43        40
          39       0.56      0.90      0.69        41
          40       1.00      0.10      0.18        41
          41       0.73      0.82      0.78        40
          42       0.74      0.80      0.77        40
          43       0.77      0.67      0.72        36
          44       0.78      0.78      0.78        37
          45       0.79      0.48      0.60        31
          46       0.76      0.78      0.77        32
          47       0.54      0.61      0.58        31
          48       0.96      0.72      0.82        32
          49       0.54      0.74      0.63        42
          50       0.97      0.76      0.85        37
          51       0.89      0.75      0.81        32
          52       0.81      0.85      0.83        34
          53       0.68      0.61      0.64        38
          54       0.70      0.90      0.79        31
          55       0.75      0.68      0.71        31
          56       0.77      0.80      0.79        30
          57       0.68      0.71      0.69        35
          58       0.82      0.68      0.74        34
          59       0.91      0.68      0.78        31
          60       0.78      0.90      0.84        31
          61       0.79      0.70      0.74        33
          62       0.83      0.94      0.88        31
          63       0.90      0.84      0.87        31
          64       0.85      0.35      0.50        31
          65       0.79      0.87      0.83        30
          66       0.53      0.56      0.55        32
          67       0.55      0.77      0.64        30
          68       0.82      0.56      0.67        32
          69       0.68      0.81      0.74        31
          70       0.64      0.60      0.62        30
          71       0.81      0.70      0.75        30
          72       1.00      0.74      0.85        31
          73       0.78      0.83      0.81        30
          74       0.95      0.70      0.81        30
          75       0.59      0.87      0.70        31
          76       0.46      0.97      0.62        31
          77       1.00      0.58      0.73        31
          78       0.83      0.85      0.84        34
          79       0.77      0.72      0.74        32
          80       0.50      0.39      0.44        31
          81       0.26      0.97      0.41        30
          82       0.87      0.67      0.75        30
          83       0.83      0.81      0.82        31
          84       0.76      0.52      0.62        31
          85       0.69      0.73      0.71        30
          86       0.86      0.51      0.64        37
          87       0.76      0.56      0.64        34
          88       0.74      0.89      0.80        44
          89       0.48      0.48      0.48        31
          90       0.55      0.78      0.65        41
          91       0.83      0.48      0.61        31
          92       0.82      0.72      0.77        32
          93       0.90      0.58      0.71        31
          94       0.84      0.81      0.83        32
          95       0.74      0.62      0.68        32
          96       0.86      0.91      0.89        34
          97       0.59      0.43      0.50        30
          98       0.53      0.86      0.66        36
          99       0.71      0.13      0.22        39
         100       0.62      0.67      0.65        30
         101       0.92      0.81      0.86        42
         102       1.00      0.42      0.60        40
         103       0.59      0.98      0.73        42
         104       0.75      0.62      0.68        39
         105       0.60      0.84      0.70        43
         106       0.97      0.75      0.85        44
         107       0.69      0.93      0.80        44
         108       0.97      0.72      0.83        40
         109       1.00      0.97      0.98        32
         110       0.77      0.74      0.75        31
         111       0.58      0.95      0.72        37
         112       0.58      0.58      0.58        31
         113       0.67      0.32      0.43        31
         114       0.44      0.39      0.41        31
         115       1.00      0.19      0.32        32
         116       0.96      0.77      0.86        31
         117       0.89      0.50      0.64        32
         118       1.00      0.67      0.80        30
         119       0.97      0.82      0.89        34

    accuracy                           0.69      4162
   macro avg       0.75      0.69      0.69      4162
weighted avg       0.75      0.69      0.69      4162

Confusion Matrix
.\classification.py:107: DeprecationWarning: This function is deprecated. Please call randint(0, 4162 + 1) instead
  imageno=np.random.random_integers(low=0, high=validation_generator.samples)
./split/val\n02105412-kelpie\n02105412_4674.jpg
0.9997495   :   (76, 'n02105412-kelpie')
0.0002315588   :   (84, 'n02106662-German_shepherd')
4.866234e-06   :   (111, 'n02113023-Pembroke')